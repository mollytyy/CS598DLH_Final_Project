{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8870248c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from DrugDrugInteraction.data import build_dataset\n",
    "from DrugDrugInteraction.utils import get_stats, write_summary, write_summary_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4088c78f-0eb8-4c7f-a115-dcb9bbb6ec6d",
   "metadata": {},
   "source": [
    "### Create PyTorch files\n",
    "this should create .pt files in the processed folder. This might take a couple minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39ce258-95d3-455f-ac71-119a81a9263e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"ZhangDDI\"  # ZhangDDI or ChChMiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7a4aa7-a0d6-4714-a251-367eb05bef63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'data/raw_data/{dataset}_train.csv', sep=\",\")\n",
    "processed_data, dataset = build_dataset(df, \"smiles_1\", \"smiles_2\", \"label\")\n",
    "torch.save(processed_data, f\"./data/processed/{dataset}_train.pt\")\n",
    "\n",
    "df = pd.read_csv(f'data/raw_data/{dataset}_valid.csv', sep=\",\")\n",
    "processed_data, dataset = build_dataset(df, \"smiles_1\", \"smiles_2\", \"label\")\n",
    "torch.save(processed_data, f\"./data/processed/{dataset}_valid.pt\")\n",
    "\n",
    "df = pd.read_csv(f'data/raw_data/{dataset}_test.csv', sep=\",\")\n",
    "processed_data, dataset = build_dataset(df, \"smiles_1\", \"smiles_2\", \"label\")\n",
    "torch.save(processed_data, f\"./data/processed/{dataset}_test.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3908f295-51a1-4b33-b451-be509fc7c75f",
   "metadata": {},
   "source": [
    "### Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830acd70-cb89-4ce7-866a-90d7ac854d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001        # Learning rate for training the model\n",
    "epochs = 10       # Number of epochs for training the model\n",
    "beta = 1.0        # Hyperparameters for balance the trade-off between prediction and compression\n",
    "tau = 1.0         # Temperature hyperparameter for CGIB_cont\n",
    "embedder = 'CGIB' # use 'CGIB' or 'CGIB_cont'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d5b231-e369-4a9f-8b9a-715abb83dfb5",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8326218e-fc1d-4c18-88ae-b5e411e5c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading dataset...\")\n",
    "start = time.time()\n",
    "\n",
    "# Load dataset\n",
    "train_set = torch.load(\"./data/processed/{}_train.pt\".format(dataset))\n",
    "valid_set = torch.load(\"./data/processed/{}_valid.pt\".format(dataset)) \n",
    "test_set = torch.load(\"./data/processed/{}_test.pt\".format(dataset))\n",
    "\n",
    "print(\"Dataset Loaded! ({:.4f} sec)\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8c2a4d-4df2-4fe4-8cc1-7ff9b8a41e3a",
   "metadata": {},
   "source": [
    "### CGIB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c4f2cd-0cb0-4062-ad4c-1b700fdd1b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.nn import Set2Set\n",
    "\n",
    "from DrugDrugInteraction.embedder import embedder\n",
    "from layers import GINE\n",
    "from DrugDrugInteraction.utils import create_batch_mask\n",
    "\n",
    "from torch_scatter import scatter_mean, scatter_add, scatter_std\n",
    "\n",
    "import time\n",
    "\n",
    "class CGIB(nn.Module):\n",
    "    \"\"\"\n",
    "    This the main class for CIGIN model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                device,\n",
    "                node_input_dim=133,\n",
    "                edge_input_dim=14,\n",
    "                node_hidden_dim=300,\n",
    "                edge_hidden_dim=300,\n",
    "                num_step_message_passing=3,\n",
    "                interaction='dot',\n",
    "                num_step_set2_set=2,\n",
    "                num_layer_set2set=1,\n",
    "                ):\n",
    "        super(CGIB, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.node_input_dim = node_input_dim\n",
    "        self.node_hidden_dim = node_hidden_dim\n",
    "        self.edge_input_dim = edge_input_dim\n",
    "        self.edge_hidden_dim = edge_hidden_dim\n",
    "        self.num_step_message_passing = num_step_message_passing\n",
    "        self.interaction = interaction\n",
    "\n",
    "        self.gather = GINE(self.node_input_dim, self.edge_input_dim, \n",
    "                            self.node_hidden_dim, self.num_step_message_passing,\n",
    "                            )\n",
    "\n",
    "        self.predictor = nn.Linear(8 * self.node_hidden_dim, 1)\n",
    "\n",
    "        self.compressor = nn.Sequential(\n",
    "            nn.Linear(2 * self.node_hidden_dim, self.node_hidden_dim),\n",
    "            nn.BatchNorm1d(self.node_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.node_hidden_dim, 1)\n",
    "            )\n",
    "        \n",
    "        self.solvent_predictor = nn.Linear(4 * self.node_hidden_dim, 4 * self.node_hidden_dim)\n",
    "        \n",
    "        self.mse_loss = torch.nn.MSELoss()\n",
    "\n",
    "        self.num_step_set2set = num_step_set2_set\n",
    "        self.num_layer_set2set = num_layer_set2set\n",
    "        self.set2set = Set2Set(2 * node_hidden_dim, self.num_step_set2set, self.num_layer_set2set)\n",
    "\n",
    "        self.init_model()\n",
    "    \n",
    "    def init_model(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(0.0)\n",
    "    \n",
    "    def compress(self, solute_features):\n",
    "        \n",
    "        p = self.compressor(solute_features)\n",
    "        temperature = 1.0\n",
    "        bias = 0.0 + 0.0001  # If bias is 0, we run into problems\n",
    "        eps = (bias - (1 - bias)) * torch.rand(p.size()) + (1 - bias)\n",
    "        gate_inputs = torch.log(eps) - torch.log(1 - eps)\n",
    "        gate_inputs = gate_inputs.to(self.device)\n",
    "        gate_inputs = (gate_inputs + p) / temperature\n",
    "        gate_inputs = torch.sigmoid(gate_inputs).squeeze()\n",
    "\n",
    "        return gate_inputs, p\n",
    "    \n",
    "    def forward(self, data, bottleneck = False, test = False):\n",
    "        solute = data[0]\n",
    "        solvent = data[1]\n",
    "        solute_len = data[2]\n",
    "        solvent_len = data[3]\n",
    "        # node embeddings after interaction phase\n",
    "        solute_features = self.gather(solute)\n",
    "        solvent_features = self.gather(solvent)\n",
    "\n",
    "        # Add normalization\n",
    "        self.solute_features = F.normalize(solute_features, dim = 1)\n",
    "        self.solvent_features = F.normalize(solvent_features, dim = 1)\n",
    "\n",
    "        # Interaction phase\n",
    "        len_map = torch.sparse.mm(solute_len.t(), solvent_len)\n",
    "\n",
    "        interaction_map = torch.mm(self.solute_features, self.solvent_features.t())\n",
    "        ret_interaction_map = torch.clone(interaction_map)\n",
    "        ret_interaction_map = interaction_map * len_map.to_dense()\n",
    "        interaction_map = interaction_map * len_map.to_dense()\n",
    "\n",
    "        self.solvent_prime = torch.mm(interaction_map.t(), self.solute_features)\n",
    "        self.solute_prime = torch.mm(interaction_map, self.solvent_features)\n",
    "\n",
    "        # Prediction phase\n",
    "        self.solute_features = torch.cat((self.solute_features, self.solute_prime), dim=1)\n",
    "        self.solvent_features = torch.cat((self.solvent_features, self.solvent_prime), dim=1)\n",
    "\n",
    "        if test:\n",
    "\n",
    "            _, self.importance = self.compress(self.solute_features)\n",
    "            self.importance = torch.sigmoid(self.importance)\n",
    "\n",
    "        if bottleneck:\n",
    "\n",
    "            lambda_pos, p = self.compress(self.solute_features)\n",
    "            lambda_pos = lambda_pos.reshape(-1, 1)\n",
    "            lambda_neg = 1 - lambda_pos\n",
    "\n",
    "            # Get Stats\n",
    "            preserve_rate = (torch.sigmoid(p) > 0.5).float().mean()\n",
    "\n",
    "            static_solute_feature = self.solute_features.clone().detach()\n",
    "            node_feature_mean = scatter_mean(static_solute_feature, solute.batch, dim = 0)[solute.batch]\n",
    "            node_feature_std = scatter_std(static_solute_feature, solute.batch, dim = 0)[solute.batch]\n",
    "            # node_feature_std, node_feature_mean = torch.std_mean(static_solute_feature, dim=0)\n",
    "            \n",
    "            noisy_node_feature_mean = lambda_pos * self.solute_features + lambda_neg * node_feature_mean\n",
    "            noisy_node_feature_std = lambda_neg * node_feature_std\n",
    "\n",
    "            noisy_node_feature = noisy_node_feature_mean + torch.rand_like(noisy_node_feature_mean) * noisy_node_feature_std\n",
    "            noisy_solute_subgraphs = self.set2set(noisy_node_feature, solute.batch)\n",
    "\n",
    "            epsilon = 1e-7\n",
    "\n",
    "            KL_tensor = 0.5 * scatter_add(((noisy_node_feature_std ** 2) / (node_feature_std + epsilon) ** 2).mean(dim = 1), solute.batch).reshape(-1, 1) + \\\n",
    "                        scatter_add((((noisy_node_feature_mean - node_feature_mean)/(node_feature_std + epsilon)) ** 2), solute.batch, dim = 0)\n",
    "            KL_Loss = torch.mean(KL_tensor)\n",
    "            \n",
    "            # Predict Solvent\n",
    "            self.solvent_features_s2s = self.set2set(self.solvent_features, solvent.batch)\n",
    "            solvent_pred_loss = self.mse_loss(self.solvent_features_s2s, self.solvent_predictor(noisy_solute_subgraphs))\n",
    "\n",
    "            # Prediction Y\n",
    "            final_features = torch.cat((noisy_solute_subgraphs, self.solvent_features_s2s), 1)\n",
    "            predictions = self.predictor(final_features)\n",
    "\n",
    "            return predictions, KL_Loss, solvent_pred_loss, preserve_rate\n",
    "        \n",
    "        else:\n",
    "\n",
    "            self.solute_features_s2s = self.set2set(self.solute_features, solute.batch)\n",
    "            self.solvent_features_s2s = self.set2set(self.solvent_features, solvent.batch)\n",
    "\n",
    "            final_features = torch.cat((self.solute_features_s2s, self.solvent_features_s2s), 1)\n",
    "            predictions = self.predictor(final_features)\n",
    "\n",
    "            if test:\n",
    "                return torch.sigmoid(predictions), ret_interaction_map\n",
    "\n",
    "            else:\n",
    "                return predictions, ret_interaction_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fd22f9-198a-4d82-8ce2-13fbefd14e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CGIB_ModelTrainer(embedder):\n",
    "    def __init__(self, train_df, valid_df, test_df, repeat, fold):\n",
    "        embedder.__init__(self, train_df, valid_df, test_df, repeat, fold)\n",
    "\n",
    "        self.model = CGIB(device = self.device).to(self.device)\n",
    "        self.optimizer = optim.Adam(params = self.model.parameters(), lr = lry)\n",
    "        self.scheduler = ReduceLROnPlateau(self.optimizer, mode='max', verbose=True)\n",
    "        \n",
    "    def train(self):        \n",
    "\n",
    "        loss_function_BCE = nn.BCEWithLogitsLoss(reduction='none')\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            self.model.train()\n",
    "            self.train_loss = 0\n",
    "            preserve = 0\n",
    "\n",
    "            start = time.time()\n",
    "\n",
    "            for bc, samples in enumerate(self.train_loader):\n",
    "                self.optimizer.zero_grad()\n",
    "                masks = create_batch_mask(samples)\n",
    "                \n",
    "                outputs, _ = self.model([samples[0].to(self.device), samples[1].to(self.device), masks[0].to(self.device), masks[1].to(self.device)])\n",
    "                loss = loss_function_BCE(outputs, samples[2].reshape(-1, 1).to(self.device).float()).mean()\n",
    "\n",
    "                # Information Bottleneck\n",
    "                outputs, KL_Loss, solvent_pred_loss, preserve_rate = self.model([samples[0].to(self.device), samples[1].to(self.device), masks[0].to(self.device), masks[1].to(self.device)], bottleneck = True)\n",
    "                loss += loss_function_BCE(outputs, samples[2].reshape(-1, 1).to(self.device).float()).mean()\n",
    "                loss += beta * KL_Loss\n",
    "                loss += beta * solvent_pred_loss\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.train_loss += loss\n",
    "                preserve += preserve_rate\n",
    "            \n",
    "            self.epoch_time = time.time() - start\n",
    "\n",
    "            self.model.eval()\n",
    "            self.evaluate(epoch)\n",
    "\n",
    "            self.scheduler.step(self.val_roc_score)\n",
    "\n",
    "            # Write Statistics\n",
    "            self.writer.add_scalar(\"stats/preservation\", preserve/bc, epoch)\n",
    "\n",
    "        self.evaluate(epoch, final = True)\n",
    "        self.writer.close()\n",
    "        \n",
    "        return self.best_test_roc, self.best_test_ap, self.best_test_f1, self.best_test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a725810-fb6e-4453-a8a0-2ced7ea00dec",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b65536-9e7e-4151-8f73-1970ef7d0749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(train_df, valid_df, test_df, repeat = 0, fold = 0):\n",
    "\n",
    "    if embedder == 'CGIB':\n",
    "        from models import CGIB_ModelTrainer\n",
    "        embedder = CGIB_ModelTrainer(train_df, valid_df, test_df, repeat, fold)\n",
    "\n",
    "    elif embedder == 'CGIB_cont':\n",
    "        from models import CGIB_cont_ModelTrainer\n",
    "        embedder = CGIB_cont_ModelTrainer(train_df, valid_df, test_df, repeat, fold)\n",
    "\n",
    "    best_roc, best_ap, best_f1, best_acc = embedder.train()\n",
    "\n",
    "    return [best_roc, best_ap, best_f1, best_acc], embedder.config_str, embedder.best_config_roc, embedder.best_config_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fce05ec-d610-4018-ac65-6fbf13fe6c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rocs, best_aps, best_f1s, best_accs = [], [], [], []\n",
    "\n",
    "stats, config_str, _, _ = summary(train_set, valid_set, test_set)\n",
    "\n",
    "# get Stats\n",
    "best_rocs.append(stats[0])\n",
    "best_aps.append(stats[1])\n",
    "best_f1s.append(stats[2])\n",
    "best_accs.append(stats[3])\n",
    "\n",
    "write_summary(dataset, embedder, config_str, stats)\n",
    "\n",
    "roc_mean, roc_std = get_stats(best_rocs)\n",
    "ap_mean, ap_std = get_stats(best_aps)\n",
    "f1_mean, f1_std = get_stats(best_f1s)\n",
    "accs_mean, accs_std = get_stats(best_accs)\n",
    "\n",
    "write_summary_total(dataset, embedder, config_str, [roc_mean, roc_std, ap_mean, ap_std, f1_mean, f1_std, accs_mean, accs_std])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a606160-8e5e-4257-ab54-87bbabbdf033",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
